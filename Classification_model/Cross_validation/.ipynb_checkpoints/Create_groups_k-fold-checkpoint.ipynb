{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir o dataset em 10 grupos (k-fold k=10)\n",
    "\n",
    "Usar k-1 grupos para treino e 1 para teste\n",
    "\n",
    "Repetir 10 vezes, cada vez com um grupo diferente no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['Age', 'AgeGroup', 'Gender', 'Height', 'Weight', 'BMI', 'FootLen', 'Ystudy', 'Illness', 'Nmedication', 'Ortho-Prosthesis', 'Disability', 'Falls12m', 'AngiotensinIIreceptorantagonist', 'HMGCoAreductaseinhibitor', 'Syntheticthyroidhormone', 'Hypercholesterolemia_total', 'Hypertension_total', 'Hypothyroidism_total', 'Normal Shoes_total', 'Sandal_FlipFlop_total', 'Dental_total', 'Corrective_lens', 'Hearing_dis_ortho_total', 'Ones']\n"
     ]
    }
   ],
   "source": [
    "# Read clean data (features <10% excluded) = 25 features\n",
    "data = pd.read_pickle(\"D:/TG-Biomed/Classification_model/data_closed_rigid_o_adjusted_clean\")\n",
    "pf50 = np.round(data[\"PF50_closed_rigid\"].values, 2)\n",
    "\n",
    "# Usar todas as 24 caracterÃ­sticas + ones\n",
    "features = data.copy()\n",
    "features.drop(\"PF50_closed_rigid\", axis=1, inplace=True)\n",
    "\n",
    "features_names = features.columns\n",
    "print('Features: ',list(features_names))\n",
    "X = features.values.astype('float')\n",
    "y = pf50.reshape(len(pf50), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 26)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Salva dado de treino/vali e dado de teste\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Separando o dataset em treino/vali e teste (treino/vali 70%, teste 30%)\n",
    "X_train_vali, X_test, y_train_vali, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Divide em classes de acordo com a os quartis do dado de treino/vali\n",
    "quart = np.quantile(y_train_vali,[0.25, 0.5, 0.75])\n",
    "print(quart)\n",
    "y_train_vali_class = np.digitize(y_train_vali, quart)\n",
    "y_test_class = np.digitize(y_test, quart)\n",
    "print((y_train_vali_class).shape)\n",
    "print((y_test_class).shape)\n",
    "\n",
    "# Salvando os dados em datasets separados\n",
    "\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('y_test_class.npy', y_test_class)\n",
    "np.save('X_train_vali.npy', X_train_vali)\n",
    "np.save('y_train_vali.npy', y_train_vali)\n",
    "np.save('y_train_vali_class.npy', y_train_vali_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create empty xlsx with header\n",
    "# tags = [\"Net\",\"random_state\",\"num_layers\",\"layers_size\",\"net_param\",\n",
    "#         \"criterion\",\"learning_rate\",\"optimizer\",\"epochs\",\n",
    "#         \"vali_best_epoch\",\"vali_best_acc\",\"vali_best_loss\",\"vali_best_R\",\n",
    "#         \"vali_sur_acc\",\"vali_sur_loss\",\"vali_sur_R\",\"vali_c_matrix\", \n",
    "#         \"vali_c_matrix_perc\", \"test_acc\",\"test_loss\",\"test_R\",\n",
    "#         \"test_predicted\",\"test_c_matrix\",\"test_c_matrix_perc\"]\n",
    "# df_nets = pd.DataFrame(columns = tags)\n",
    "# print(df_nets)\n",
    "# df_nets.to_excel ('classification_nets_empty.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zika",
   "language": "python",
   "name": "zika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
