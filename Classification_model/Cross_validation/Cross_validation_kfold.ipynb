{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from pickle import dump, load\n",
    "import os\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, layers_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(input_size, layers_size[0])])\n",
    "        for i in range(0, self.num_layers-2):\n",
    "            self.linears.extend([nn.Linear(layers_size[i], layers_size[i+1])])              \n",
    "        self.linears.append(nn.Linear(layers_size[-1], output_size))\n",
    "\n",
    "# Última camada sem função de ativação --> crossentropy já aplica softmax\n",
    "# ReLU em intermediárias\n",
    "    def forward(self, x):\n",
    "        for layer in self.linears[0:-1]:                   \n",
    "            x = F.relu(layer(x))\n",
    "        x = (self.linears[-1](x))\n",
    "        return(x)\n",
    "\n",
    "# # Aplicando função de ativação na última camada tbm\n",
    "# ### Tentar mudar pra sigmoide se deixar a normalização de 0,1\n",
    "#     def forward(self, x):\n",
    "#         for layer in self.linears:                   \n",
    "#             x = torch.sigmoid(layer(x))\n",
    "# #             x = F.relu(layer(x))\n",
    "#         return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonRepeatedRandomInt(low, upper, N):\n",
    "        import numpy as np\n",
    "        import random\n",
    "        \n",
    "        numbers = np.arange(low, upper, 1)\n",
    "        random.shuffle(numbers)\n",
    "        shuffleNumbers = np.array(numbers)[0:int(N)]\n",
    "                \n",
    "        return shuffleNumbers\n",
    "\n",
    "def createSurrogate(X):\n",
    "    Xsur  = np.zeros_like(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        Xsur[:,i] = X[nonRepeatedRandomInt(0, X.shape[0], X.shape[0]),i]\n",
    "    return Xsur\n",
    "\n",
    "def save_checkpoint(state, is_best, filename):\n",
    "    if is_best:\n",
    "        torch.save(state, filename)\n",
    "#         print('*****Saved epoch: %d *****' % (state['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Net, random_state, num_layers, layers_size, net_param, criterion, learning_rate, optimizer, epochs, vali_best_epoch, vali_best_acc, vali_best_loss, vali_best_R, vali_sur_acc, vali_sur_loss, vali_sur_R, vali_c_matrix, vali_c_matrix_perc, test_acc, test_loss, test_R, test_predicted, test_c_matrix, test_c_matrix_perc, test_leave_out_acc, test_leave_out_loss, test_leave_out_R, test_leave_out_predicted, test_leave_out_c_matrix, test_leave_out_c_matrix_perc]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create empty xlsx with header\n",
    "tags = [\"Net\",\"random_state\",\"num_layers\",\"layers_size\",\"net_param\",\n",
    "        \"criterion\",\"learning_rate\",\"optimizer\",\"epochs\",\n",
    "        \"vali_best_epoch\",\"vali_best_acc\",\"vali_best_loss\",\"vali_best_R\",\n",
    "        \"vali_sur_acc\",\"vali_sur_loss\",\"vali_sur_R\",\"vali_c_matrix\", \n",
    "        \"vali_c_matrix_perc\", \"test_acc\",\"test_loss\",\"test_R\",\n",
    "        \"test_predicted\",\"test_c_matrix\",\"test_c_matrix_perc\",\n",
    "        \"test_leave_out_acc\",\"test_leave_out_loss\",\"test_leave_out_R\",\n",
    "        \"test_leave_out_predicted\",\"test_leave_out_c_matrix\",\"test_leave_out_c_matrix_perc\"]\n",
    "df_nets = pd.DataFrame(columns = tags)\n",
    "print(df_nets)\n",
    "df_nets.to_excel ('classification_nets_empty.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net</th>\n",
       "      <th>random_state</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>layers_size</th>\n",
       "      <th>net_param</th>\n",
       "      <th>criterion</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>epochs</th>\n",
       "      <th>vali_best_epoch</th>\n",
       "      <th>...</th>\n",
       "      <th>vali_sur_R</th>\n",
       "      <th>vali_c_matrix</th>\n",
       "      <th>vali_c_matrix_perc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_R</th>\n",
       "      <th>test_predicted</th>\n",
       "      <th>test_c_matrix</th>\n",
       "      <th>test_c_matrix_perc</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>8322</td>\n",
       "      <td>4</td>\n",
       "      <td>[13, 2, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.079</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041337</td>\n",
       "      <td>[[5 3 0 0]\\n [2 5 1 2]\\n [2 0 1 1]\\n [2 1 1 3]]</td>\n",
       "      <td>[[62.5        37.5         0.          0.     ...</td>\n",
       "      <td>46</td>\n",
       "      <td>25.496305</td>\n",
       "      <td>0.336126</td>\n",
       "      <td>[0 0 3 0 0 0 1 1 1 1 1 0 0 1 0 3 0 1 1 3 0 0 0...</td>\n",
       "      <td>[[15  4  1  3]\\n [ 8  6  0  1]\\n [ 4  5  3  1]...</td>\n",
       "      <td>[[65.2173913  17.39130435  4.34782609 13.04347...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 8, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.022</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>7900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107848</td>\n",
       "      <td>[[3 0 0 0]\\n [1 4 4 1]\\n [2 3 2 2]\\n [0 0 1 6]]</td>\n",
       "      <td>[[100.           0.           0.           0. ...</td>\n",
       "      <td>44</td>\n",
       "      <td>39.951607</td>\n",
       "      <td>0.459575</td>\n",
       "      <td>[0 0 3 1 0 3 2 0 1 2 3 0 0 3 2 3 0 3 0 3 0 3 3...</td>\n",
       "      <td>[[16  2  2  3]\\n [ 5  4  3  3]\\n [ 3  1  3  6]...</td>\n",
       "      <td>[[69.56521739  8.69565217  8.69565217 13.04347...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540</td>\n",
       "      <td>6369</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>10800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>[[5 0 1 0]\\n [0 1 4 2]\\n [2 1 0 0]\\n [4 4 3 2]]</td>\n",
       "      <td>[[83.33333333  0.         16.66666667  0.     ...</td>\n",
       "      <td>44</td>\n",
       "      <td>52.059341</td>\n",
       "      <td>0.306450</td>\n",
       "      <td>[0 0 3 0 0 2 3 1 1 2 0 2 0 1 1 2 1 0 0 2 0 2 2...</td>\n",
       "      <td>[[13  3  6  1]\\n [ 4  6  4  1]\\n [ 4  1  7  1]...</td>\n",
       "      <td>[[56.52173913 13.04347826 26.08695652  4.34782...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26263</td>\n",
       "      <td>1675</td>\n",
       "      <td>4</td>\n",
       "      <td>[11, 23, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.031</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>1400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084188</td>\n",
       "      <td>[[6 1 0 0]\\n [3 0 0 3]\\n [5 3 1 1]\\n [2 2 0 2]]</td>\n",
       "      <td>[[85.71428571 14.28571429  0.          0.     ...</td>\n",
       "      <td>46</td>\n",
       "      <td>7.935145</td>\n",
       "      <td>0.442801</td>\n",
       "      <td>[0 0 3 0 0 0 2 0 0 3 0 0 0 1 0 3 0 2 0 2 1 3 2...</td>\n",
       "      <td>[[19  2  1  1]\\n [ 9  2  2  2]\\n [ 6  1  4  2]...</td>\n",
       "      <td>[[82.60869565  8.69565217  4.34782609  4.34782...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29059</td>\n",
       "      <td>1170</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 11, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.068</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>1700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136046</td>\n",
       "      <td>[[4 5 1 0]\\n [4 2 1 2]\\n [2 1 1 0]\\n [0 1 2 3]]</td>\n",
       "      <td>[[40.         50.         10.          0.     ...</td>\n",
       "      <td>46</td>\n",
       "      <td>53.844082</td>\n",
       "      <td>0.332687</td>\n",
       "      <td>[3 0 0 1 0 2 3 0 1 2 1 0 0 0 1 2 0 2 0 3 1 3 1...</td>\n",
       "      <td>[[11  7  3  2]\\n [ 4  7  1  3]\\n [ 4  1  6  2]...</td>\n",
       "      <td>[[47.82608696 30.43478261 13.04347826  8.69565...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31465</td>\n",
       "      <td>539</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 18, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.041</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>5800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068774</td>\n",
       "      <td>[[2 0 2 0]\\n [3 2 1 1]\\n [4 2 3 0]\\n [2 1 3 3]]</td>\n",
       "      <td>[[50.          0.         50.          0.     ...</td>\n",
       "      <td>49</td>\n",
       "      <td>41.712780</td>\n",
       "      <td>0.293188</td>\n",
       "      <td>[1 0 0 0 0 0 1 1 1 0 0 0 0 3 1 3 0 2 0 3 0 3 0...</td>\n",
       "      <td>[[16  1  4  2]\\n [ 7  6  0  2]\\n [ 6  1  4  2]...</td>\n",
       "      <td>[[69.56521739  4.34782609 17.39130435  8.69565...</td>\n",
       "      <td>47.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31773</td>\n",
       "      <td>2078</td>\n",
       "      <td>4</td>\n",
       "      <td>[21, 4, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.034</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179166</td>\n",
       "      <td>[[4 0 1 0]\\n [9 1 1 0]\\n [5 1 0 0]\\n [3 1 0 3]]</td>\n",
       "      <td>[[80.          0.         20.          0.     ...</td>\n",
       "      <td>49</td>\n",
       "      <td>8.416088</td>\n",
       "      <td>0.479702</td>\n",
       "      <td>[0 0 3 0 0 0 2 0 0 1 0 0 0 0 0 1 0 2 0 3 0 2 0...</td>\n",
       "      <td>[[19  1  1  2]\\n [11  1  3  0]\\n [ 5  1  6  1]...</td>\n",
       "      <td>[[82.60869565  4.34782609  4.34782609  8.69565...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3645</td>\n",
       "      <td>9437</td>\n",
       "      <td>4</td>\n",
       "      <td>[8, 6, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.061</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>1400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218495</td>\n",
       "      <td>[[7 0 0 0]\\n [2 1 0 0]\\n [5 1 3 1]\\n [5 0 1 3]]</td>\n",
       "      <td>[[100.           0.           0.           0. ...</td>\n",
       "      <td>46</td>\n",
       "      <td>14.726895</td>\n",
       "      <td>0.246033</td>\n",
       "      <td>[1 0 3 0 0 0 1 0 2 0 0 0 0 1 1 3 0 2 2 3 0 1 3...</td>\n",
       "      <td>[[18  0  2  3]\\n [ 6  5  1  3]\\n [ 7  1  4  1]...</td>\n",
       "      <td>[[78.26086957  0.          8.69565217 13.04347...</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55704</td>\n",
       "      <td>3160</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.080</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201490</td>\n",
       "      <td>[[4 0 1 3]\\n [3 1 1 2]\\n [4 1 5 2]\\n [0 1 0 1]]</td>\n",
       "      <td>[[50.          0.         12.5        37.5    ...</td>\n",
       "      <td>46</td>\n",
       "      <td>12.075455</td>\n",
       "      <td>0.349757</td>\n",
       "      <td>[3 2 2 0 0 0 1 2 3 3 0 2 0 0 1 2 3 2 0 3 0 0 0...</td>\n",
       "      <td>[[17  2  2  2]\\n [ 5  4  3  3]\\n [ 3  3  5  2]...</td>\n",
       "      <td>[[73.91304348  8.69565217  8.69565217  8.69565...</td>\n",
       "      <td>47.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8601</td>\n",
       "      <td>5715</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 12, 4]</td>\n",
       "      <td>&lt;bound method Module.parameters of Net(\\n  (li...</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>0.080</td>\n",
       "      <td>Adam</td>\n",
       "      <td>50000</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102979</td>\n",
       "      <td>[[4 2 1 3]\\n [1 5 0 1]\\n [2 0 1 3]\\n [1 2 2 1]]</td>\n",
       "      <td>[[40.         20.         10.         30.     ...</td>\n",
       "      <td>46</td>\n",
       "      <td>11.518072</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>[0 0 3 0 0 3 3 1 1 3 1 2 0 1 3 3 1 2 1 3 0 1 0...</td>\n",
       "      <td>[[14  4  1  4]\\n [ 5  5  0  5]\\n [ 3  4  4  2]...</td>\n",
       "      <td>[[60.86956522 17.39130435  4.34782609 17.39130...</td>\n",
       "      <td>47.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Net  random_state  num_layers  layers_size  \\\n",
       "0    171          8322           4   [13, 2, 4]   \n",
       "1    199            82           4    [4, 8, 4]   \n",
       "2   1540          6369           4    [3, 7, 4]   \n",
       "3  26263          1675           4  [11, 23, 4]   \n",
       "4  29059          1170           4  [12, 11, 4]   \n",
       "5  31465           539           4  [12, 18, 4]   \n",
       "6  31773          2078           4   [21, 4, 4]   \n",
       "7   3645          9437           4    [8, 6, 4]   \n",
       "8  55704          3160           4    [3, 7, 4]   \n",
       "9   8601          5715           4   [7, 12, 4]   \n",
       "\n",
       "                                           net_param         criterion  \\\n",
       "0  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "1  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "2  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "3  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "4  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "5  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "6  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "7  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "8  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "9  <bound method Module.parameters of Net(\\n  (li...  CrossEntropyLoss   \n",
       "\n",
       "   learning_rate optimizer  epochs  vali_best_epoch  ...  vali_sur_R  \\\n",
       "0          0.079      Adam   50000             8100  ...   -0.041337   \n",
       "1          0.022      Adam   50000             7900  ...    0.107848   \n",
       "2          0.002      Adam   50000            10800  ...   -0.010383   \n",
       "3          0.031      Adam   50000             1400  ...   -0.084188   \n",
       "4          0.068      Adam   50000             1700  ...    0.136046   \n",
       "5          0.041      Adam   50000             5800  ...   -0.068774   \n",
       "6          0.034      Adam   50000              500  ...    0.179166   \n",
       "7          0.061      Adam   50000             1400  ...   -0.218495   \n",
       "8          0.080      Adam   50000              400  ...    0.201490   \n",
       "9          0.080      Adam   50000              100  ...    0.102979   \n",
       "\n",
       "                                     vali_c_matrix  \\\n",
       "0  [[5 3 0 0]\\n [2 5 1 2]\\n [2 0 1 1]\\n [2 1 1 3]]   \n",
       "1  [[3 0 0 0]\\n [1 4 4 1]\\n [2 3 2 2]\\n [0 0 1 6]]   \n",
       "2  [[5 0 1 0]\\n [0 1 4 2]\\n [2 1 0 0]\\n [4 4 3 2]]   \n",
       "3  [[6 1 0 0]\\n [3 0 0 3]\\n [5 3 1 1]\\n [2 2 0 2]]   \n",
       "4  [[4 5 1 0]\\n [4 2 1 2]\\n [2 1 1 0]\\n [0 1 2 3]]   \n",
       "5  [[2 0 2 0]\\n [3 2 1 1]\\n [4 2 3 0]\\n [2 1 3 3]]   \n",
       "6  [[4 0 1 0]\\n [9 1 1 0]\\n [5 1 0 0]\\n [3 1 0 3]]   \n",
       "7  [[7 0 0 0]\\n [2 1 0 0]\\n [5 1 3 1]\\n [5 0 1 3]]   \n",
       "8  [[4 0 1 3]\\n [3 1 1 2]\\n [4 1 5 2]\\n [0 1 0 1]]   \n",
       "9  [[4 2 1 3]\\n [1 5 0 1]\\n [2 0 1 3]\\n [1 2 2 1]]   \n",
       "\n",
       "                                  vali_c_matrix_perc  test_acc  test_loss  \\\n",
       "0  [[62.5        37.5         0.          0.     ...        46  25.496305   \n",
       "1  [[100.           0.           0.           0. ...        44  39.951607   \n",
       "2  [[83.33333333  0.         16.66666667  0.     ...        44  52.059341   \n",
       "3  [[85.71428571 14.28571429  0.          0.     ...        46   7.935145   \n",
       "4  [[40.         50.         10.          0.     ...        46  53.844082   \n",
       "5  [[50.          0.         50.          0.     ...        49  41.712780   \n",
       "6  [[80.          0.         20.          0.     ...        49   8.416088   \n",
       "7  [[100.           0.           0.           0. ...        46  14.726895   \n",
       "8  [[50.          0.         12.5        37.5    ...        46  12.075455   \n",
       "9  [[40.         20.         10.         30.     ...        46  11.518072   \n",
       "\n",
       "     test_R                                     test_predicted  \\\n",
       "0  0.336126  [0 0 3 0 0 0 1 1 1 1 1 0 0 1 0 3 0 1 1 3 0 0 0...   \n",
       "1  0.459575  [0 0 3 1 0 3 2 0 1 2 3 0 0 3 2 3 0 3 0 3 0 3 3...   \n",
       "2  0.306450  [0 0 3 0 0 2 3 1 1 2 0 2 0 1 1 2 1 0 0 2 0 2 2...   \n",
       "3  0.442801  [0 0 3 0 0 0 2 0 0 3 0 0 0 1 0 3 0 2 0 2 1 3 2...   \n",
       "4  0.332687  [3 0 0 1 0 2 3 0 1 2 1 0 0 0 1 2 0 2 0 3 1 3 1...   \n",
       "5  0.293188  [1 0 0 0 0 0 1 1 1 0 0 0 0 3 1 3 0 2 0 3 0 3 0...   \n",
       "6  0.479702  [0 0 3 0 0 0 2 0 0 1 0 0 0 0 0 1 0 2 0 3 0 2 0...   \n",
       "7  0.246033  [1 0 3 0 0 0 1 0 2 0 0 0 0 1 1 3 0 2 2 3 0 1 3...   \n",
       "8  0.349757  [3 2 2 0 0 0 1 2 3 3 0 2 0 0 1 2 3 2 0 3 0 0 0...   \n",
       "9  0.345833  [0 0 3 0 0 3 3 1 1 3 1 2 0 1 3 3 1 2 1 3 0 1 0...   \n",
       "\n",
       "                                       test_c_matrix  \\\n",
       "0  [[15  4  1  3]\\n [ 8  6  0  1]\\n [ 4  5  3  1]...   \n",
       "1  [[16  2  2  3]\\n [ 5  4  3  3]\\n [ 3  1  3  6]...   \n",
       "2  [[13  3  6  1]\\n [ 4  6  4  1]\\n [ 4  1  7  1]...   \n",
       "3  [[19  2  1  1]\\n [ 9  2  2  2]\\n [ 6  1  4  2]...   \n",
       "4  [[11  7  3  2]\\n [ 4  7  1  3]\\n [ 4  1  6  2]...   \n",
       "5  [[16  1  4  2]\\n [ 7  6  0  2]\\n [ 6  1  4  2]...   \n",
       "6  [[19  1  1  2]\\n [11  1  3  0]\\n [ 5  1  6  1]...   \n",
       "7  [[18  0  2  3]\\n [ 6  5  1  3]\\n [ 7  1  4  1]...   \n",
       "8  [[17  2  2  2]\\n [ 5  4  3  3]\\n [ 3  3  5  2]...   \n",
       "9  [[14  4  1  4]\\n [ 5  5  0  5]\\n [ 3  4  4  2]...   \n",
       "\n",
       "                                  test_c_matrix_perc    new_acc  \n",
       "0  [[65.2173913  17.39130435  4.34782609 13.04347...  45.454545  \n",
       "1  [[69.56521739  8.69565217  8.69565217 13.04347...  45.454545  \n",
       "2  [[56.52173913 13.04347826 26.08695652  4.34782...  45.454545  \n",
       "3  [[82.60869565  8.69565217  4.34782609  4.34782...  45.454545  \n",
       "4  [[47.82608696 30.43478261 13.04347826  8.69565...  45.454545  \n",
       "5  [[69.56521739  4.34782609 17.39130435  8.69565...  47.272727  \n",
       "6  [[82.60869565  4.34782609  4.34782609  8.69565...  45.454545  \n",
       "7  [[78.26086957  0.          8.69565217 13.04347...  45.454545  \n",
       "8  [[73.91304348  8.69565217  8.69565217  8.69565...  47.272727  \n",
       "9  [[60.86956522 17.39130435  4.34782609 17.39130...  47.272727  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load initial xlsx to save\n",
    "df_cross_validation = pd.read_excel('classification_nets_empty.xlsx', index_col=None, header=0)\n",
    "\n",
    "# Read xlsx with nets info\n",
    "df_nets = pd.read_excel('/TG-Biomed/Classification_model/SELECTED_NETS.xlsx', index_col=None, header=0)\n",
    "df_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [13, 2, 4]\n",
       "1      [4, 8, 4]\n",
       "2      [3, 7, 4]\n",
       "3    [11, 23, 4]\n",
       "4    [12, 11, 4]\n",
       "5    [12, 18, 4]\n",
       "6     [21, 4, 4]\n",
       "7      [8, 6, 4]\n",
       "8      [3, 7, 4]\n",
       "9     [7, 12, 4]\n",
       "Name: layers_size, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_layers_size = df_nets['layers_size']\n",
    "net_layers_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.079\n",
       "1    0.022\n",
       "2    0.002\n",
       "3    0.031\n",
       "4    0.068\n",
       "5    0.041\n",
       "6    0.034\n",
       "7    0.061\n",
       "8    0.080\n",
       "9    0.080\n",
       "Name: learning_rate, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_learning_rate = df_nets['learning_rate']\n",
    "net_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\ipykernel_launcher.py:169: RuntimeWarning: invalid value encountered in true_divide\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\ipykernel_launcher.py:169: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "D:\\anaconda3\\envs\\zika\\lib\\site-packages\\ipykernel_launcher.py:169: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('ResultsKfold') == False: \n",
    "    os.makedirs('ResultsKfold')\n",
    "\n",
    "# Load data\n",
    "for kcont in range(1, 11):\n",
    "    print('k'+str(kcont))\n",
    "    X_train_vali = np.load('k'+str(kcont)+'_X_train.npy')\n",
    "    y_train_vali_class = np.load('k'+str(kcont)+'_y_train_class.npy')\n",
    "    X_test = np.load('k'+str(kcont)+'_X_test.npy')\n",
    "    y_test_class = np.load('k'+str(kcont)+'_y_test_class.npy')\n",
    "    X_leave_out = np.load('X_leave_out.npy')\n",
    "    y_class_leave_out = np.load('y_class_leave_out.npy')    \n",
    "        \n",
    "    # Separando o treino da vali (treino 80%, validação 20%)\n",
    "    random_state = 42\n",
    "    X_train, X_vali, y_train_class, y_vali_class = train_test_split(X_train_vali, y_train_vali_class, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Escalamento e Transformação dos dados\n",
    "    scaler_x = RobustScaler(with_centering=True)\n",
    "    X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "    X_vali_scaled = scaler_x.transform(X_vali)\n",
    "    X_test_scaled = scaler_x.transform(X_test)\n",
    "    X_leave_out_scaled = scaler_x.transform(X_leave_out)    \n",
    "    \n",
    "    # save the scaler\n",
    "    dump(scaler_x, open('./ResultsKfold/k'+str(kcont)+'_scaler_x.pkl', 'wb'))\n",
    "\n",
    "    # Create Surrogate\n",
    "    X_vali_scaled_sur = createSurrogate(X_vali_scaled)\n",
    "\n",
    "    for netcont in range(0, 10):\n",
    "        number_str = str(netcont)\n",
    "        zero_filled_number = number_str.zfill(2)\n",
    "\n",
    "        # Parâmetros da rede\n",
    "        torch.manual_seed(1234)\n",
    "        num_layers = 4\n",
    "        layers_size = np.fromstring(net_layers_size[netcont][1:-1], dtype=int, sep=',')\n",
    "        net = Net(input_size=X_train.shape[1], num_layers=num_layers, layers_size=layers_size , output_size=4)\n",
    "\n",
    "        # Choose optmizer and loss function\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        learning_rate = net_learning_rate[netcont]\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "        # Treinamento \n",
    "        epochs = 50000\n",
    "        loss_train = np.zeros(epochs)\n",
    "        loss_vali = np.zeros(epochs)\n",
    "        acc_vali = np.zeros(epochs)\n",
    "        best_acc = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            inputs = torch.autograd.Variable(torch.Tensor(X_train_scaled.astype(np.float32)).float())\n",
    "            targets = torch.autograd.Variable(torch.Tensor(y_train_class).long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = net(inputs)\n",
    "            loss = criterion(out, targets.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train[epoch] = loss.item()\n",
    "\n",
    "            # Validação\n",
    "            if epoch == 0 or (epoch + 1) % 100 == 0:\n",
    "                inputs_vali = torch.autograd.Variable(torch.Tensor(X_vali_scaled.astype(np.float32)).float())\n",
    "                targets_vali = torch.autograd.Variable(torch.Tensor(y_vali_class).long())\n",
    "                out_vali = net(inputs_vali)\n",
    "                loss_v = criterion(out_vali, targets_vali.squeeze())\n",
    "                loss_vali[epoch] = loss_v.item()\n",
    "                _, predicted = torch.max(out_vali.data, 1)\n",
    "\n",
    "                # Calcula acurácia\n",
    "                error_count = y_vali_class.size - np.count_nonzero((targets_vali.squeeze() == predicted) .numpy())\n",
    "                acc_vali[epoch] = 100 * torch.sum(targets_vali.squeeze() == predicted) / y_vali_class.size\n",
    "\n",
    "                r_vali = np.corrcoef(predicted.detach().numpy().squeeze(), targets_vali.detach().numpy().squeeze())[0,1]\n",
    "\n",
    "                # remember best acc and save best model\n",
    "                is_best = acc_vali[epoch] >= best_acc\n",
    "                best_acc = max(acc_vali[epoch], best_acc)\n",
    "                save_checkpoint({'epoch': epoch + 1,\n",
    "                                #'arch': args.arch,\n",
    "                                'state_dict': net.state_dict(),\n",
    "                                'best_acc': best_acc,\n",
    "                                'loss': loss_v.item(),\n",
    "                                'R-corrcoef': r_vali,\n",
    "                                'optimizer' : optimizer.state_dict(),\n",
    "                                }, is_best, './ResultsKfold/k'+str(kcont)+'_'+zero_filled_number+'_model_best.pth.tar')\n",
    "\n",
    "                if is_best:                \n",
    "                    inputs_vali_sur = torch.autograd.Variable(torch.Tensor(X_vali_scaled_sur.astype(np.float32)).float())\n",
    "                    targets_vali_sur = torch.autograd.Variable(torch.Tensor(y_vali_class).long())\n",
    "                    out_vali_sur = net(inputs_vali_sur)\n",
    "                    loss_v_sur = criterion(out_vali_sur, targets_vali_sur.squeeze())\n",
    "                    _, predicted_sur = torch.max(out_vali_sur.data, 1)\n",
    "\n",
    "                    # Calcula acurácia\n",
    "                    error_count_sur = y_vali_class.size - np.count_nonzero((targets_vali_sur.squeeze() == predicted_sur) .numpy())\n",
    "                    acc_vali_sur = 100 * torch.sum(targets_vali_sur.squeeze() == predicted_sur) / y_vali_class.size\n",
    "\n",
    "                    r_vali_sur = np.corrcoef(predicted_sur.detach().numpy().squeeze(), targets_vali_sur.detach().numpy().squeeze())[0,1]\n",
    "\n",
    "                    # Confusion matrix\n",
    "                    C_vali = confusion_matrix(targets_vali,predicted, labels=[0, 1, 2, 3])\n",
    "                    C_perc_vali = C_vali/np.sum(C_vali, axis=1, keepdims=True)*100\n",
    "\n",
    "    #             print('Epoch %d Loss: %.4f' % (epoch + 1, loss.item()))\n",
    "    #             print('   Validation Loss: %.4f' % (loss_v.item()))\n",
    "    #             print('   Errors: %d; Accuracy: %d%%' % (error_count, acc_vali[epoch]))\n",
    "    #             print('   R-corrcoef: %s' % (str(r_vali)))\n",
    "\n",
    "        # Load best model\n",
    "        checkpoint = torch.load('./ResultsKfold/k'+str(kcont)+'_'+zero_filled_number+'_model_best.pth.tar')\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        # Teste\n",
    "        # Avaliando a acurácia do modelo utilizando os dados de teste transformados\n",
    "        inputs = torch.autograd.Variable(torch.Tensor(X_test_scaled.astype(np.float32)).float())\n",
    "        targets = torch.autograd.Variable(torch.Tensor(y_test_class).long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = net(inputs)\n",
    "        loss = criterion(out, targets.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(out.data, 1)       \n",
    "\n",
    "        error_count = y_test_class.size - np.count_nonzero((targets.squeeze() == predicted) .numpy())\n",
    "        acc = 100 * torch.sum(targets.squeeze() == predicted) /  y_test_class.size\n",
    "        r = np.corrcoef(predicted.detach().numpy().squeeze(), targets.detach().numpy().squeeze())[0,1]\n",
    "\n",
    "    #     print('Errors: %d; Accuracy: %d%%' % (error_count, acc))\n",
    "    #     print('Teste Loss: %.4f' % (loss.item()))\n",
    "    #     print('R-corrcoef: %s' % (str(r)))\n",
    "\n",
    "        # Confusion matrix\n",
    "        C = confusion_matrix(targets,predicted, labels=[0, 1, 2, 3])\n",
    "        C_perc = C/np.sum(C, axis=1, keepdims=True)*100\n",
    "\n",
    "\n",
    "        # Teste LEAVE OUT\n",
    "        # Avaliando a acurácia do modelo utilizando os dados de teste LEAVE OUT transformados\n",
    "        inputs_leave_out = torch.autograd.Variable(torch.Tensor(X_leave_out_scaled.astype(np.float32)).float())\n",
    "        targets_leave_out = torch.autograd.Variable(torch.Tensor(y_class_leave_out).long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_leave_out = net(inputs_leave_out)\n",
    "        loss_leave_out = criterion(out_leave_out, targets_leave_out.squeeze())\n",
    "        loss_leave_out.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_leave_out = torch.max(out_leave_out.data, 1)       \n",
    "\n",
    "        error_count_leave_out = y_class_leave_out.size - np.count_nonzero((targets_leave_out.squeeze() == predicted_leave_out) .numpy())\n",
    "        acc_leave_out = 100 * torch.sum(targets_leave_out.squeeze() == predicted_leave_out) /  y_class_leave_out.size\n",
    "        r_leave_out = np.corrcoef(predicted_leave_out.detach().numpy().squeeze(), targets_leave_out.detach().numpy().squeeze())[0,1]\n",
    "\n",
    "    #     print('Errors: %d; Accuracy: %d%%' % (error_count, acc))\n",
    "    #     print('Teste Loss: %.4f' % (loss.item()))\n",
    "    #     print('R-corrcoef: %s' % (str(r)))\n",
    "\n",
    "        # Confusion matrix\n",
    "        C_leave_out = confusion_matrix(targets_leave_out,predicted_leave_out, labels=[0, 1, 2, 3])\n",
    "        C_leave_out_perc = C_leave_out/np.sum(C_leave_out, axis=1, keepdims=True)*100\n",
    "        \n",
    "        net_info = {\n",
    "                \"Net\": ['k'+str(kcont)+'_'+zero_filled_number],\n",
    "                \"random_state\": [random_state],\n",
    "                \"num_layers\": [num_layers],\n",
    "                \"layers_size\": [layers_size],\n",
    "                \"net_param\": [net.parameters],\n",
    "                \"criterion\": ['CrossEntropyLoss'],\n",
    "                \"learning_rate\": [learning_rate],\n",
    "                \"optimizer\": ['Adam'],\n",
    "                \"epochs\": [epochs],\n",
    "                \"vali_best_epoch\": [checkpoint['epoch']],\n",
    "                \"vali_best_acc\": [checkpoint['best_acc']],\n",
    "                \"vali_best_loss\": [checkpoint['loss']],\n",
    "                \"vali_best_R\": [checkpoint['R-corrcoef']],\n",
    "                \"vali_sur_acc\": [acc_vali_sur.item()],\n",
    "                \"vali_sur_loss\": [loss_v_sur.item()],\n",
    "                \"vali_sur_R\": [r_vali_sur],\n",
    "                \"vali_c_matrix\": [C_vali],\n",
    "                \"vali_c_matrix_perc\": [C_perc_vali],\n",
    "                \"test_acc\": [acc.item()],\n",
    "                \"test_loss\": [loss.item()],\n",
    "                \"test_R\": [r],\n",
    "                \"test_predicted\": [predicted.numpy()],\n",
    "                \"test_c_matrix\": [C],\n",
    "                \"test_c_matrix_perc\": [C_perc],\n",
    "                \"test_leave_out_acc\": [acc_leave_out.item()],\n",
    "                \"test_leave_out_loss\": [loss_leave_out.item()],\n",
    "                \"test_leave_out_R\": [r_leave_out],\n",
    "                \"test_leave_out_predicted\": [predicted_leave_out.numpy()],\n",
    "                \"test_leave_out_c_matrix\": [C_leave_out],\n",
    "                \"test_leave_out_c_matrix_perc\": [C_leave_out_perc]\n",
    "                }\n",
    "\n",
    "        tags = [\"Net\",\"random_state\",\"num_layers\",\"layers_size\",\"net_param\",\n",
    "                \"criterion\",\"learning_rate\",\"optimizer\",\"epochs\",\n",
    "                \"vali_best_epoch\",\"vali_best_acc\",\"vali_best_loss\",\"vali_best_R\",\n",
    "                \"vali_sur_acc\",\"vali_sur_loss\",\"vali_sur_R\",\"vali_c_matrix\", \n",
    "                \"vali_c_matrix_perc\", \"test_acc\",\"test_loss\",\"test_R\",\n",
    "                \"test_predicted\",\"test_c_matrix\",\"test_c_matrix_perc\",\n",
    "                \"test_leave_out_acc\",\"test_leave_out_loss\",\"test_leave_out_R\",\n",
    "                \"test_leave_out_predicted\",\"test_leave_out_c_matrix\",\"test_leave_out_c_matrix_perc\"]\n",
    "        df_cross_validation = df_cross_validation.append(pd.DataFrame(net_info, columns = tags), ignore_index=True)\n",
    "\n",
    "        # Add suffix to identify saved info\n",
    "        df_cross_validation.to_excel ('cross_vali_kfold.xlsx', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zika",
   "language": "python",
   "name": "zika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
